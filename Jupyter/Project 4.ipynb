{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Project 4\n",
    "## Arman Rostami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, several machine learning algorithms including Decision Trees and Random Forests are studied and implemented. The goal is to predict having heart disease given some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following funciton prints accuracy of given predictions using correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(data_labels, predict_labels):\n",
    "    accuracy = accuracy_score(data_labels, predict_labels)\n",
    "    print(\"Accuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting to test and train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data is splitted to train and test data. 80% of data is randomly chosen to be for training data and others for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bools = np.random.rand(len(data)) < 0.8\n",
    "train_data = data[train_bools]\n",
    "test_data = data[~train_bools]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees are one of the simplest and yet most successful forms of machine learning algorithms. A decision tree represents a function that takes as input a vector of attribute values and\n",
    "returns a “decision”—a single output value. The input and output values can be discrete or\n",
    "continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree reaches its decision by performing a sequence of tests. Each internal\n",
    "node in the tree corresponds to a test of the value of one of the input attributes, $A_i$ , and\n",
    "the branches from the node are labeled with the possible values of the attribute, $A_i = v_{ik}$ .\n",
    "Each leaf node in the tree specifies a value to be returned by the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following sections show implementation of Decision Tree using python's sklearn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Featrues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features (of course except feature) are used to create decision tree. List of features is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n"
     ]
    }
   ],
   "source": [
    "features = list(train_data.columns[:-1])\n",
    "print(\"Features:\", features, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using sklearn's DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn's DecisionTreeClassifier is used to create decision tree based on given features and target of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features = train_data[features]\n",
    "sample_targets = train_data['target']\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree = decision_tree.fit(sample_features, sample_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = decision_tree.predict(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7627118644067796\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(test_data['target'], predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstraping is a powerful statistical method for estimating a quantity from a data sample. It can be used to estimate summary statistics such as the mean or standard deviation. In this method estimates are calculated by averaging estimates from multiple small data samples. Bootstraping reduces variance by reducing sensitivity to small noises in data. One method to implement bootstraping is to randomly sample with replacement from known observations and create new samples which are less likely identical to the initial sample since replacement is used. Then these samples can be used to generate results based on their values. (e.g. calculating average of results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap Aggregation or bagging a simple and very powerful ensemble method which is based on bootstraping and is used to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. Bagging reduces variance and helps to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is a modeling error that occurs when model fits the given training data so much that it would be inaccurate in predicting the outcomes of the untrained data. Overfitting typically happens in Decision Trees since Desicion Tree tries to create best tree to perfectly fit all samples in the training data set. Methods such as pruning and random forests can be used to overcome overfitting in decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is a method used with Decision Trees. In this method several samples are generated from training date like the bagging model and on each new samples, a Decision Tree is implemented with one difference with bagging Decision Tree method: It also selects a subset of features to split nodes in Desicion Tree. Theses features are selected randomly and number of features to select is specified as a parameter to algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following sections show steps to implement the Random Forest algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1) Generate New Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five new samples with size of 150 are generated from training data with replacing allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SAMPLES_COUNT = 5\n",
    "NEW_SAMPLE_SIZE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_sample(data, sample_size):\n",
    "    chosen_data_bools = np.random.choice(len(data), sample_size, replace=True)\n",
    "    return data.iloc[chosen_data_bools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = list()\n",
    "for i in range(NEW_SAMPLES_COUNT):\n",
    "    new_sample = generate_new_sample(train_data, NEW_SAMPLE_SIZE)\n",
    "    new_samples.append(new_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2) Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previous section, Bagging method is implemented in the following codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Decision Tree for each new sample set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_trees = [tree.DecisionTreeClassifier() for i in range(NEW_SAMPLES_COUNT)]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training created Decision trees with corresponding sample set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(new_samples):\n",
    "    sample_features = sample[features]\n",
    "    sample_targets = sample['target']\n",
    "    decision_trees[i].fit(sample_features, sample_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering predictions of each Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_predicts = list()\n",
    "for i, desicion_tree in enumerate(decision_trees):\n",
    "    predicts = decision_trees[i].predict(test_data[features])\n",
    "    bagging_predicts.append(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a voter to assign label to given test. Voter selects label which is used more in Decision Trees results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predicts = list()\n",
    "for i in range(len(test_data)):\n",
    "    target_count = 0\n",
    "    \n",
    "    for predicts in bagging_predicts:\n",
    "        target_count += predicts[i]\n",
    "    \n",
    "    target = int(target_count >= (len(bagging_predicts) / 2))\n",
    "    final_predicts.append(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8983050847457628\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(test_data['target'], final_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3) Examine Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are examined by deleting them and calculating accuracy of the Decision Tree classifier with deleted feature to find out deleting which feature results in better accuracy. Results are dependent on data. **In this example** deleting age feature results in less loss in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Feature: age\n",
      "Accuracy: 0.8813559322033898\n",
      "***\n",
      "Deleted Feature: sex\n",
      "Accuracy: 0.8135593220338984\n",
      "***\n",
      "Deleted Feature: cp\n",
      "Accuracy: 0.8305084745762712\n",
      "***\n",
      "Deleted Feature: trestbps\n",
      "Accuracy: 0.7627118644067796\n",
      "***\n",
      "Deleted Feature: chol\n",
      "Accuracy: 0.7627118644067796\n",
      "***\n",
      "Deleted Feature: fbs\n",
      "Accuracy: 0.8305084745762712\n",
      "***\n",
      "Deleted Feature: restecg\n",
      "Accuracy: 0.7796610169491526\n",
      "***\n",
      "Deleted Feature: thalach\n",
      "Accuracy: 0.7796610169491526\n",
      "***\n",
      "Deleted Feature: exang\n",
      "Accuracy: 0.7796610169491526\n",
      "***\n",
      "Deleted Feature: oldpeak\n",
      "Accuracy: 0.7627118644067796\n",
      "***\n",
      "Deleted Feature: slope\n",
      "Accuracy: 0.7966101694915254\n",
      "***\n",
      "Deleted Feature: ca\n",
      "Accuracy: 0.6610169491525424\n",
      "***\n",
      "Deleted Feature: thal\n",
      "Accuracy: 0.711864406779661\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "for deleted_feature in features:\n",
    "    available_features = [feature for feature in features if feature != deleted_feature]\n",
    "    sample_features = train_data[available_features]\n",
    "    sample_targets = train_data['target']\n",
    "    \n",
    "    decision_tree = tree.DecisionTreeClassifier()\n",
    "    decision_tree = decision_tree.fit(sample_features, sample_targets)\n",
    "    \n",
    "    predicts = decision_tree.predict(test_data[available_features])\n",
    "    print('Deleted Feature: %s' % deleted_feature)\n",
    "    print_accuracy(test_data['target'], predicts)\n",
    "    print('***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-4) Decision Tree by Choosing Random Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five features are randomly chosen and given to Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Features:\n",
      "['age' 'slope' 'sex' 'thal' 'restecg']\n",
      "Accuracy: 0.6610169491525424\n"
     ]
    }
   ],
   "source": [
    "RANDOM_FEATURES_COUNT = 5\n",
    "\n",
    "available_features = np.random.choice(features, RANDOM_FEATURES_COUNT, replace=False)\n",
    "sample_features = train_data[available_features]\n",
    "sample_targets = train_data['target']\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree = decision_tree.fit(sample_features, sample_targets)\n",
    "\n",
    "predicts = decision_tree.predict(test_data[available_features])\n",
    "\n",
    "print(\"Chosen Features:\")\n",
    "print(available_features)\n",
    "print_accuracy(test_data['target'], predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-5) Random Forest Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using previous sections, Random Forest method is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Decision Tree for each new sample set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_trees = [tree.DecisionTreeClassifier() for i in range(NEW_SAMPLES_COUNT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create random feature sets for each Desicion Tree classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_features = [np.random.choice(features, RANDOM_FEATURES_COUNT, replace=False) for i in range(NEW_SAMPLES_COUNT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training created decision trees with corresponding sample set and random features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(new_samples):\n",
    "    available_features = random_forest_features[i]\n",
    "    sample_features = sample[available_features]\n",
    "    sample_targets = sample['target']\n",
    "    decision_trees[i].fit(sample_features, sample_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering predictions of each Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_predicts = list()\n",
    "for i, desicion_tree in enumerate(decision_trees):\n",
    "    predicts = decision_trees[i].predict(test_data[random_forest_features[i]])\n",
    "    bagging_predicts.append(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a voter to assign label to given test. Voter selects label which is used more in Decision Trees results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predicts = list()\n",
    "for i in range(len(test_data)):\n",
    "    target_count = 0\n",
    "    \n",
    "    for predicts in bagging_predicts:\n",
    "        target_count += predicts[i]\n",
    "    \n",
    "    target = int(target_count >= (len(bagging_predicts) / 2))\n",
    "    final_predicts.append(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847457627118644\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(test_data['target'], final_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on results and previous sections, bagging reduces variance and overfitting by ignoring specific samples with replacing samples, It helps to have a better accuracy on a new test set. Random Forest also reduces overfitting by selecting a subset of features so that the resulting predictions from all of the subtrees have less correlation which results to better accuracy. Also note that dataset was not perfect and there are cases in which normal decision tree gives more accuracy or Random Forest method may not work perfectly since it's using random features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
